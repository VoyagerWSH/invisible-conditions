{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0657fb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using GPU:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../wilds_source/')\n",
    "\n",
    "from relative_prevalence_benchmark.gpu_utils import restrict_GPU_pytorch\n",
    "restrict_GPU_pytorch('0')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from wilds_source.wilds import get_dataset\n",
    "from wilds_source.wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "from wilds_source.wilds.common.grouper import CombinatorialGrouper\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.insert(0, '../wilds_source/examples/')\n",
    "from transforms import initialize_transform, getBertTokenizer\n",
    "from algorithms.initializer import initialize_algorithm\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab661d6c",
   "metadata": {},
   "source": [
    "### Load original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff923af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test_public_expanded.csv')\n",
    "individual_annotations = pd.read_csv('../data/toxicity_individual_annotations.csv')\n",
    "\n",
    "train = train[train['identity_annotator_count'] > 0]\n",
    "test = test[test['identity_annotator_count'] > 0]\n",
    "# 20% of the comments are annotated for identity, and these are the comments we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30639206",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_annotation = individual_annotations.groupby('id').first().reset_index()\n",
    "all_annotations = individual_annotations.groupby('id').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a5fe1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0bf568b370>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAanElEQVR4nO3de3BW9b3v8ffHgM3xbiV2ELRgB4pguAahoC2UdgtsPViQs0Er4qUMWnXP2J7CnO4tzmh3d4utbFotpYioo4HWC1pHa2u5KUoP0SJyqZYqSDYdblorUi/B7/njCTkhPMmzElZui89rJmPW+v2etb4/Ej8sfs96fksRgZmZtX/HtHYBZmaWDge6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llRKsGuqSFknZJ2pCw//+StEnSRkkPNXd9ZmbtiVrzPnRJXwT2AfdHxLkF+vYAfgl8OSLekXR6ROxqiTrNzNqDVr1Cj4hVwNu190n6nKTfSHpJ0nOSelU3fQO4KyLeqX6tw9zMrJa2OIc+H7gxIgYB3wburt7fE+gpabWkNZJGt1qFZmZtUIfWLqA2SScAw4BfSTq4+1PV/+0A9ABGAF2B5ySdGxF/a+EyzczapDYV6OT+xfC3iOifp60SWBMRHwNvSnqNXMCvbcH6zMzarDY15RIRfycX1hMBlNOvunkpMLJ6fydyUzBvtEadZmZtUWvftlgOvAh8XlKlpGuAy4FrJL0CbATGVXd/BtgraROwHPjfEbG3Neo2M2uLWvW2RTMzS0+bmnIxM7Oma7U3RTt16hTdunVrrdObmbVLL7300p6IKMnX1mqB3q1bNyoqKlrr9GZm7ZKkbfW1ecrFzCwjHOhmZhnhQDczy4i29klRM2tGH3/8MZWVlXzwwQetXYoVUFxcTNeuXenYsWPi1zjQzY4ilZWVnHjiiXTr1o1a6yVZGxMR7N27l8rKSrp37574dZ5yMTuKfPDBB5x22mkO8zZOEqeddlqj/yXlQDc7yjjM24em/Jwc6GZmGeE5dLOj2DWL0l19+p6pgwv2qays5Jvf/CabNm3ik08+4aKLLmL27Nkce+yxqdbSXObMmcO0adM47rjjUumXpnYZ6Gn/EjZGkl9YM8svIhg/fjzXXXcdjz/+OAcOHGDatGl897vfZfbs2a1dXiJz5szh61//eqJAT9KvtgMHDlBUVNTk2jzlYmYtZtmyZRQXF3PVVVcBUFRUxJ133snChQvZv38/ixYtYvz48YwePZoePXrwne98p+a1v/3tb/nCF77AwIEDmThxIvv27Tvs+L/4xS8YPHgw/fr1Y8KECezfvx+AqVOnctNNNzFs2DDOPvtsHn74YQBWrFjBiBEjuPTSS+nVqxeXX345B1eg/f3vf8+AAQMoLS3l6quv5sMPP2Tu3Lns2LGDkSNHMnLkSACuu+46ysrK6NOnD7NmzQLI26+8vJzS0lLOPfdcZsyYUVPzCSecwC233MKQIUN48cUXj+jP14FuZi1m48aNDBo06JB9J510EmeddRZbtmwBYN26dSxZsoRXX32VJUuWsH37dvbs2cPtt9/Os88+y8svv0xZWRk//vGPDzv++PHjWbt2La+88grnnHMO99xzT03bX//6V55//nmefPJJZs6cWbP/j3/8I3PmzGHTpk288cYbrF69mg8++ICpU6fW1FFVVcXPfvYzbrrpJs444wyWL1/O8uXLAfje975HRUUF69evZ+XKlaxfv/6wfjt27GDGjBksW7aMdevWsXbtWpYuXQrA+++/z7nnnssf/vAHzj///CP683Wgm1mLiYi8d2/U3j9q1ChOPvlkiouL6d27N9u2bWPNmjVs2rSJ4cOH079/f+677z62bTt8jaoNGzZwwQUXUFpayoMPPsjGjRtr2i655BKOOeYYevfuzc6dO2v2n3feeXTt2pVjjjmG/v37s3XrVl577TW6d+9Oz549AbjyyitZtWpV3jH98pe/ZODAgQwYMICNGzeyadOmw/qsXbuWESNGUFJSQocOHbj88strjldUVMSECRMa8adYv4Jz6JIWAhcBuyLi3Hr6jADmAB2BPRHxpVSqM7NM6dOnD4888sgh+/7+97+zfft2Pve5z/HSSy/xqU99qqatqKiIqqoqIoKvfvWrlJeXN3j8qVOnsnTpUvr168eiRYtYsWJFTVvt49Z+sE9950vizTff5I477mDt2rWceuqpTJ06Ne+94w0dr7i4+IjmzWtLcoW+CBhdX6OkU4C7gf8ZEX2AialUZmaZM2rUKPbv38/9998P5N4E/Na3vsXUqVMbfPNw6NChrF69umZaZv/+/bz++uuH9Xvvvffo3LkzH3/8MQ8++GCT6+zVqxdbt26tOd8DDzzAl76Uu0498cQTee+994DcX0bHH388J598Mjt37uTpp5+uOUbtfkOGDGHlypXs2bOHAwcOUF5eXnO8NBW8Qo+IVZK6NdDlMuDRiHiruv+ulGozs2bW0ndtSeKxxx7j+uuv57bbbuOTTz5h7Nix/Md//EeDryspKWHRokVMnjyZDz/8EIDbb7+9ZkrkoNtuu40hQ4bw2c9+ltLS0ppAbazi4mLuvfdeJk6cSFVVFYMHD2b69OkATJs2jTFjxtC5c2eWL1/OgAED6NOnD2effTbDhw+vOUbdft///vcZOXIkEcHYsWMZN25cfadvskTPFK0O9CfzTblImkNuqqUPcCLwXxFxfz3HmQZMAzjrrLMG5ZsDS8K3LZo1zebNmznnnHNauwxLKN/PS9JLEVGWr38ab4p2AAYB/wxcCPy7pJ75OkbE/Igoi4iykpK8T1AyM7MmSuODRZXk3gh9H3hf0iqgH3D4BJeZmTWbNK7QHwcukNRB0nHAEGBzCsc1M7NGSHLbYjkwAugkqRKYRW7OnIiYFxGbJf0GWA98AiyIiA3NV7KZmeWT5C6XyQn6zAbax0IMZmYZ5U+KmpllRLtcbdHMUvLQv6R7vMuWJOr22GOPMX78eDZv3kyvXr0A2Lp1KxdddBEbNmxgxYoV3HHHHTz55JPp1pfAihUrOPbYYxk2bFgq/VqSr9DNrMWVl5dz/vnns3jx4tYu5TArVqzghRdeSK1fbVVVVU0tKxEHupm1qH379rF69WruueeeRgf61q1bueCCCxg4cCADBw6sCdSGlsHt1q0bs2bNYuDAgZSWlvKnP/0JgLfffptLLrmEvn37MnToUNavX8/WrVuZN28ed955J/379+e5557j17/+NUOGDGHAgAF85StfYefOnXn7bdu2jVGjRtG3b19GjRrFW2+9BeTWl7n55psZOXIkM2bMYOXKlfTv35/+/fszYMCAJn+aNR9PuZhZi1q6dCmjR4+mZ8+efPrTn+bll19m4MCBiV57+umn87vf/Y7i4mL+/Oc/M3nyZCoqKoDcMrgbN27kjDPOYPjw4axevbpmOdpOnTrx8ssvc/fdd3PHHXewYMECZs2axYABA1i6dCnLli1jypQprFu3junTp3PCCSfw7W9/G4B33nmHNWvWIIkFCxbwwx/+kB/96EeH9bv44ouZMmUKV155JQsXLuSmm26qWSL39ddf59lnn6WoqIiLL76Yu+66i+HDh7Nv3z6Ki4tT+7P1FbqZtajy8nImTZoEwKRJkwquoFjbxx9/zDe+8Q1KS0uZOHHiIUvV5lsG96Dx48cDMGjQoJr9zz//PFdccQUAX/7yl9m7dy/vvvvuYeesrKzkwgsvpLS0lNmzZx+yJG9tL774IpdddhkAV1xxBc8//3xN28SJE2tWVBw+fDg333wzc+fO5W9/+xsdOqR3Xe1AN7MWs3fvXpYtW8a1115Lt27dmD17NkuWLEm8XO2dd97JZz7zGV555RUqKir46KOPatryLYNbt632/nznzLdW+4033sgNN9zAq6++ys9//vO8y+PmU/tYxx9/fM33M2fOZMGCBfzjH/9g6NChNVNAaXCgm1mLefjhh5kyZQrbtm1j69atbN++ne7dux9yNduQd999l86dO3PMMcfwwAMPcODAgSbX8sUvfrFmid0VK1bQqVMnTjrppEOWvT14zi5dugBw33331eyv22/YsGE17wk8+OCD9T596C9/+QulpaXMmDGDsrKyVAPdc+hmR7OEtxmmpby8/JDHvwFMmDCBhx566JDnbNbn+uuvZ8KECfzqV79i5MiRh1z5Ntatt97KVVddRd++fTnuuONqwvriiy/m0ksv5fHHH+cnP/kJt956KxMnTqRLly4MHTqUN998M2+/uXPncvXVVzN79mxKSkq499578553zpw5LF++nKKiInr37s2YMWOaPIa6Ei2f2xzKysri4JsZjeXlc82axsvnti+tsXyumZm1AQ50M7OMcKCbHWVaa5rVGqcpPycHutlRpLi4mL179zrU27iIYO/evY3+0JHvcjE7inTt2pXKykp2797d2qVYAcXFxXTt2rVRr3Ggmx1FOnbsSPfu3Vu7DGsmBadcJC2UtEtSg08hkjRY0gFJl6ZXnpmZJZVkDn0RMLqhDpKKgB8Az6RQk5mZNUHBQI+IVcDbBbrdCDwC7EqjKDMza7wjvstFUhfga8C8BH2nSaqQVOE3ZczM0pXGbYtzgBkRUXCVnIiYHxFlEVFWUlKSwqnNzOygNO5yKQMWVy8V2QkYK6kqIpamcGwzM0voiAM9ImrugZK0CHjSYW5m1vIKBrqkcmAE0ElSJTAL6AgQEQXnzc3MrGUUDPSImJz0YBEx9YiqMTOzJvNaLmZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwjHOhmZhnhQDczywgHuplZRrTLh0TfuPPfWvHsfsqembVNvkI3M8sIB7qZWUY40M3MMsKBbmaWEQUDXdJCSbskbain/XJJ66u/XpDUL/0yzcyskCRX6IuA0Q20vwl8KSL6ArcB81Ooy8zMGinJI+hWSerWQPsLtTbXAF1TqMvMzBop7Tn0a4Cn62uUNE1ShaSK3bt3p3xqM7OjW2qBLmkkuUCfUV+fiJgfEWURUVZSUpLWqc3MjJQ+KSqpL7AAGBMRe9M4ppmZNc4RX6FLOgt4FLgiIl4/8pLMzKwpCl6hSyoHRgCdJFUCs4COABExD7gFOA24WxJAVUSUNVfBZmaWX5K7XCYXaL8WuDa1iszMrEn8SVEzs4xwoJuZZYQD3cwsIxzoZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEFA13SQkm7JG2op12S5kraImm9pIHpl2lmZoUkuUJfBIxuoH0M0KP6axrwsyMvy8zMGqtgoEfEKuDtBrqMA+6PnDXAKZI6p1WgmZklk8Ycehdge63tyup9h5E0TVKFpIrdu3encGozMzsojUBXnn2Rr2NEzI+IsogoKykpSeHUZmZ2UBqBXgmcWWu7K7AjheOamVkjpBHoTwBTqu92GQq8GxF/TeG4ZmbWCB0KdZBUDowAOkmqBGYBHQEiYh7wFDAW2ALsB65qrmLNzKx+BQM9IiYXaA/gm6lVZGZmTeJPipqZZYQD3cwsIxzoZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjEgU6JJGS3pN0hZJM/O0nyzp15JekbRRkp9aZGbWwgoGuqQi4C5gDNAbmCypd51u3wQ2RUQ/co+r+5GkY1Ou1czMGpDkCv08YEtEvBERHwGLgXF1+gRwoiQBJwBvA1WpVmpmZg1KEuhdgO21tiur99X2U+AcYAfwKvCvEfFJ3QNJmiapQlLF7t27m1iymZnlkyTQlWdf1Nm+EFgHnAH0B34q6aTDXhQxPyLKIqKspKSkkaWamVlDkgR6JXBmre2u5K7Ea7sKeDRytgBvAr3SKdHMzJJIEuhrgR6Sule/0TkJeKJOn7eAUQCSPgN8HngjzULNzKxhHQp1iIgqSTcAzwBFwMKI2ChpenX7POA2YJGkV8lN0cyIiD3NWLeZmdVRMNABIuIp4Kk6++bV+n4H8E/plmZmZo3hT4qamWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwjHOhmZhnhQDczywgHuplZRjjQzcwywoFuZpYRDnQzs4xIFOiSRkt6TdIWSTPr6TNC0jpJGyWtTLdMMzMrpOATiyQVAXcBXyX3wOi1kp6IiE21+pwC3A2Mjoi3JJ3eTPWamVk9klyhnwdsiYg3IuIjYDEwrk6fy4BHI+ItgIjYlW6ZZmZWSJJA7wJsr7VdWb2vtp7AqZJWSHpJ0pR8B5I0TVKFpIrdu3c3rWIzM8srSaArz76os90BGAT8M3Ah8O+Seh72ooj5EVEWEWUlJSWNLtbMzOpXcA6d3BX5mbW2uwI78vTZExHvA+9LWgX0A15PpUozMysoyRX6WqCHpO6SjgUmAU/U6fM4cIGkDpKOA4YAm9Mt1czMGlLwCj0iqiTdADwDFAELI2KjpOnV7fMiYrOk3wDrgU+ABRGxoTkLNzOzQyWZciEingKeqrNvXp3t2cDs9EozM7PG8CdFzcwywoFuZpYRDnQzs4xwoJuZZYQD3cwsIxzoZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGJAp0SaMlvSZpi6SZDfQbLOmApEvTK9HMzJIoGOiSioC7gDFAb2CypN719PsBuUfVmZlZC0tyhX4esCUi3oiIj4DFwLg8/W4EHgF2pVifmZkllCTQuwDba21XVu+rIakL8DXgkOeM1iVpmqQKSRW7d+9ubK1mZtaAJIGuPPuizvYcYEZEHGjoQBExPyLKIqKspKQkYYlmZpZEhwR9KoEza213BXbU6VMGLJYE0AkYK6kqIpamUaSZmRWWJNDXAj0kdQf+G5gEXFa7Q0R0P/i9pEXAkw5zM7OWVTDQI6JK0g3k7l4pAhZGxEZJ06vbG5w3NzOzlpHkCp2IeAp4qs6+vEEeEVOPvCwzM2ssf1LUzCwjHOhmZhnhQDczywgHuplZRjjQzcwywoFuZpYRDnQzs4xwoJuZZYQD3cwsIxzoZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWVEokCXNFrSa5K2SJqZp/1ySeurv16Q1C/9Us3MrCEFA11SEXAXMAboDUyW1LtOtzeBL0VEX+A2YH7ahZqZWcOSXKGfB2yJiDci4iNgMTCudoeIeCEi3qneXAN0TbdMMzMrJEmgdwG219qurN5Xn2uAp/M1SJomqUJSxe7du5NXaWZmBSUJdOXZF3k7SiPJBfqMfO0RMT8iyiKirKSkJHmVZmZWUIcEfSqBM2ttdwV21O0kqS+wABgTEXvTKc/MzJJKEuhrgR6SugP/DUwCLqvdQdJZwKPAFRHxeupVGjz0L6137suWtN65zSyxgoEeEVWSbgCeAYqAhRGxUdL06vZ5wC3AacDdkgCqIqKs+co2M7O6klyhExFPAU/V2Tev1vfXAtemW1ob1ZpXymZmDUgU6GZmWXPNorWtdu57pg5uluP6o/9mZhnhQDczywgHuplZRjjQzcwywoFuZpYRDnQzs4xwoJuZZYQD3cwsIxzoZmYZ4U+KmuXTWks8eCE0OwK+QjczywhfoVvb5YXQzBrFV+hmZhnhQDczywhPuZi1JX4z1o5AokCXNBr4L3JPLFoQEf9Zp13V7WOB/cDUiHg55VrNLIta7b2Sb7fSeZtPwUCXVATcBXyV3AOj10p6IiI21eo2BuhR/TUE+Fn1f82sPfAb0JmQ5Ar9PGBLRLwBIGkxMA6oHejjgPsjIoA1kk6R1Dki/pp6xdby/D+7ZdCNO/+tFc/+TLMcNUmgdwG219qu5PCr73x9ugCHBLqkacC06s19kl5rVLX/XydgTxNf2155zEcHj/loMFNHMubP1teQJNCVZ180oQ8RMR+Yn+CcDRckVURE2ZEepz3xmI8OHvPRobnGnOS2xUrgzFrbXYEdTehjZmbNKEmgrwV6SOou6VhgEvBEnT5PAFOUMxR41/PnZmYtq+CUS0RUSbqB3Cx+EbAwIjZKml7dPg94itwti1vI3bZ4VfOVDKQwbdMOecxHB4/56NAsY1buxhQzM2vv/NF/M7OMcKCbmWVEmw50SaMlvSZpi6SZedolaW51+3pJA1ujzjQlGPPl1WNdL+kFSf1ao840FRpzrX6DJR2QdGlL1tcckoxZ0ghJ6yRtlLSypWtMW4Lf7ZMl/VrSK9Vjbu734pqVpIWSdknaUE97+vkVEW3yi9wbsH8BzgaOBV4BetfpMxZ4mtx98EOBP7R23S0w5mHAqdXfjzkaxlyr3zJyb8Bf2tp1t8DP+RRyn8Y+q3r79NauuwXG/H+AH1R/XwK8DRzb2rUfwZi/CAwENtTTnnp+teUr9JolByLiI+DgkgO11Sw5EBFrgFMkdW7pQlNUcMwR8UJEvFO9uYbcPf/tWZKfM8CNwCPArpYsrpkkGfNlwKMR8RZARLT3cScZcwAnVi/2dwK5QK9q2TLTExGryI2hPqnnV1sO9PqWE2hsn/akseO5htzf8O1ZwTFL6gJ8DZjXgnU1pyQ/557AqZJWSHpJ0pQWq655JBnzT4FzyH0o8VXgXyPik5Ypr1Wknl9teT301JYcaEcSj0fSSHKBfn6zVtT8kox5DjAjIg7kLt7avSRj7gAMAkYB/wN4UdKaiHi9uYtrJknGfCGwDvgy8Dngd5Kei4i/N3NtrSX1/GrLgX40LjmQaDyS+gILgDERsbeFamsuScZcBiyuDvNOwFhJVRGxtEUqTF/S3+09EfE+8L6kVUA/oL0GepIxXwX8Z+QmmLdIehPoBfzflimxxaWeX215yuVoXHKg4JglnQU8ClzRjq/Wais45ojoHhHdIqIb8DBwfTsOc0j2u/04cIGkDpKOI7fC6eYWrjNNScb8Frl/kSDpM8DngTdatMqWlXp+tdkr9GibSw40q4RjvgU4Dbi7+oq1KtrxSnUJx5wpScYcEZsl/QZYD3xC7klheW9/aw8S/pxvAxZJepXcdMSMiGi3y+pKKgdGAJ0kVQKzgI7QfPnlj/6bmWVEW55yMTOzRnCgm5llhAPdzCwjHOhmZhnhQDczywgHuplZRjjQzcwy4v8B9yx1UUACDSUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(one_annotation['toxic'], alpha=.7, label='One annotator')\n",
    "plt.hist(all_annotations['toxic'], alpha=.7, label='All annotators')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ec65e",
   "metadata": {},
   "source": [
    "### Table of example comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff46637",
   "metadata": {},
   "outputs": [],
   "source": [
    "identities = ['asian', 'atheist', 'bisexual',\n",
    "               'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
    "               'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
    "               'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
    "               'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
    "               'other_sexual_orientation', 'physical_disability',\n",
    "               'psychiatric_or_mental_illness', 'transgender', 'white']\n",
    "train['n_identities'] = (train[identities] > 0).sum(axis=1)\n",
    "train = train[~train['comment_text'].str.contains('http')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7e4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "nontoxic_train = train[train['target']  < .5]\n",
    "toxic_train = train[train['target'] > .5]\n",
    "\n",
    "nontoxic_train_no_identities = nontoxic_train[nontoxic_train['n_identities'] == 0]\n",
    "nontoxic_train_w_identities = nontoxic_train[nontoxic_train['n_identities'] > 1]\n",
    "toxic_train_no_identities =  toxic_train[toxic_train['n_identities'] == 0]\n",
    "toxic_train_one_identity =  toxic_train[toxic_train['n_identities'] == 1]\n",
    "toxic_train_mult_identities = toxic_train[toxic_train['n_identities'] >1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4286a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_row_to_identities_list(row):\n",
    "    included_identities = \"\"\n",
    "    for identity in identities:\n",
    "        if row[identity] > 0:\n",
    "            included_identities += (identity.replace('_', ' ')) + \",\"\n",
    "    if len(included_identities):\n",
    "        return included_identities[:-1]\n",
    "    return included_identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "48b018f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_sample, seed = 3, 99\n",
    "a = nontoxic_train_no_identities.sample(n=n_to_sample, random_state=seed)\n",
    "b = nontoxic_train_w_identities.sample(n=n_to_sample, random_state=seed)\n",
    "c = toxic_train_no_identities.sample(n=n_to_sample, random_state=seed)\n",
    "d = toxic_train_one_identity.sample(n=n_to_sample, random_state=seed)\n",
    "e =  toxic_train_mult_identities.sample(n=n_to_sample, random_state=seed)\n",
    "\n",
    "kk = pd.concat([a, b, c, d, e])\n",
    "kk['identities_list'] = kk.apply(map_row_to_identities_list, axis=1)\n",
    "kk['toxicity'] = kk['target'] > .5\n",
    "kk['toxicity'] = kk['toxicity'].astype(int)\n",
    "kk['comment_text_pref'] = kk['comment_text'].str[:150] + \"...\"\n",
    "kk = kk[['comment_text_pref', 'toxicity', 'identities_list']]\n",
    "kk.rename(columns = {'comment_text_pref': 'Comment Text', \n",
    "                     'toxicity': 'Toxicity',  \n",
    "                     'identities_list': 'List of Identities'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c3f29c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{p{0.5\\linewidth}|c|r}}\n",
      "\\toprule\n",
      "                                                                                                                                                Comment Text &  Toxicity &               List of Identities \\\\\n",
      "\\midrule\n",
      " Donald Trump is an American, living in American, and  paying taxes under the American system- please try and keep up.\\n\\nStrangely enough, when I got my... &         0 &                                  \\\\\n",
      "   \"There are even some places (a McDonald’s in Kaneohe was one) who have entire employee-application booths set up right there, like the ones at job fai... &         0 &                                  \\\\\n",
      "                                     Hunting is a long walk on an empty stomach, glad to hear your hunt is over and your heart and stomach are both full.... &         0 &                                  \\\\\n",
      "   I can't think of anyone less Christian than Trump. Anyone who puts the bottom line ahead of the welfare of their fellow woman and man, does not have t... &         0 &            christian,female,male \\\\\n",
      "   Governor Walker wants $666,000,000 removed from the private sector.  This is shock and awe. It will cause astronomical harm to every man, woman, child... &         0 &  female,male,physical disability \\\\\n",
      "   Women's thousands of years of oppression from men will soon be over. They will be allowed into combat. And...they will have to register for the draft.... &         0 &                      female,male \\\\\n",
      "                                                                                         The bots and trolls only come out on articles attacking Trudeau.... &         1 &                                  \\\\\n",
      "                                                                                                Gross! I'm so sorry this child was exposed to such filth!... &         1 &                                  \\\\\n",
      "   Absolute rubbish. Trump based his campaign on insult and character assassination. He picked a fight with the media, the intelligence services, career ... &         1 &                                  \\\\\n",
      "   This is mental sickness, pure and simple. Spare me the \"culture\" debate. This whale lived for 200 years. 200 YEARS. And this punk kid comes and kills ... &         1 &    psychiatric or mental illness \\\\\n",
      " Who? Oh yea. The no talent obnoxious gay guy that's famous only for being gay. His 15 seconds of fame are up. Nobody care. Next. \\n\\nA drunk driver with... &         1 &        homosexual gay or lesbian \\\\\n",
      "   Buddha believes his the universal truth as truth.  There nothing but bunch of hypocrites who are wolves in sheep clothing. Greedy and evil Buddhists w... &         1 &                         buddhist \\\\\n",
      "                                                       What if the hat was more blatant such as \"I hate blacks and women\".  Would it still be just a hat?... &         1 &                     black,female \\\\\n",
      "   MJ, you are absolutely a useful idiot, heres how, Donald J. Trump is a liar, no one not even you can deny that. Donald J. Trump has cheated thousands ... &         1 &                      female,male \\\\\n",
      "                       What in the world?\\n\\nI see articles on Fox News almost daily about female teachers having sex with their adolesent male students.... &         1 &                      female,male \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "\n",
    "    latex_str = kk.to_latex(escape=False,  index=False, column_format='p{0.5\\linewidth}|c|r}')\n",
    "    print(latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c031a33",
   "metadata": {},
   "source": [
    "### Apply pretrained model to this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa15983",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = .5\n",
    "full_dataset = get_dataset(dataset='civilcomments', download=True)\n",
    "   \n",
    "config_dict = pickle.load(open('./cc_config.pkl', 'rb'))\n",
    "config = Namespace(**config_dict)\n",
    "config.algorithm = 'ERM'\n",
    "\n",
    "train_transform = initialize_transform(transform_name=config.transform,\n",
    "                                      config=config,\n",
    "                                      dataset=full_dataset,\n",
    "                                      is_training=True)\n",
    "eval_transform = initialize_transform(transform_name=config.transform,\n",
    "                                      config=config,\n",
    "                                      dataset=full_dataset,\n",
    "                                      is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27b680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_str = \"\"\n",
    "# def get_idx_in_text_array(full_dataset, substr):\n",
    "#     text_array = full_dataset._text_array\n",
    "#     idxs = [i for i in range(len(text_array)) if substr in text_array[i]]\n",
    "#     if len(idxs):\n",
    "#         return idxs[0]\n",
    "#     return 0\n",
    "# idx = get_idx_in_text_array(full_dataset, text_str)\n",
    "# full_dataset._y_array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7907a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_dataset.get_subset('test', transform=eval_transform)\n",
    "data_loader = get_eval_loader('standard', data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd4fdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = defaultdict(dict)\n",
    "train_grouper = CombinatorialGrouper(dataset=full_dataset, groupby_fields=config.groupby_fields)\n",
    "for split in full_dataset.split_dict.keys():\n",
    "    if split=='train':\n",
    "        transform = train_transform\n",
    "        verbose = True\n",
    "    elif split == 'val':\n",
    "        transform = eval_transform\n",
    "        verbose = True\n",
    "    else:\n",
    "        transform = eval_transform\n",
    "        verbose = False\n",
    "    # Get subset\n",
    "    datasets[split]['dataset'] = full_dataset.get_subset(\n",
    "        split,\n",
    "        frac=config.frac,\n",
    "        transform=transform)\n",
    "\n",
    "    if split == 'train':\n",
    "        datasets[split]['loader'] = get_train_loader(\n",
    "            loader=config.train_loader,\n",
    "            dataset=datasets[split]['dataset'],\n",
    "            batch_size=config.batch_size,\n",
    "            uniform_over_groups=config.uniform_over_groups,\n",
    "            grouper=train_grouper,\n",
    "            distinct_groups=config.distinct_groups,\n",
    "            n_groups_per_batch=config.n_groups_per_batch,\n",
    "        **config.loader_kwargs)\n",
    "else:\n",
    "    datasets[split]['loader'] = get_eval_loader(\n",
    "        loader=config.eval_loader,\n",
    "        dataset=datasets[split]['dataset'],\n",
    "        grouper=train_grouper,\n",
    "        batch_size=config.batch_size,\n",
    "        **config.loader_kwargs)\n",
    "\n",
    "# Set fields\n",
    "datasets[split]['split'] = split\n",
    "datasets[split]['name'] = full_dataset.split_names[split]\n",
    "datasets[split]['verbose'] = verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5de01e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertClassifier(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(alg.model)\n",
    "alg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff5358da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertClassifier: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertClassifier were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "alg = initialize_algorithm(config, datasets, train_grouper)\n",
    "alg.load_state_dict(torch.load('../best_model.pth')['algorithm'])\n",
    "alg.model.cuda()\n",
    "alg.model.eval()\n",
    "alg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84cb10b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c9ca268b104eb7aaca962a8b25e0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16723 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n",
      "torch.Size([8, 300, 768]) torch.Size([1, 300, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a7487bcfd5f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mjj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistilbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mall_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         sa_output = self.attention(\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim_per_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ipv/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_feats = []\n",
    "metadata = []\n",
    "all_labels = []\n",
    "toxicity = []\n",
    "it = iter(data_loader)\n",
    "i = 0 \n",
    "for batch in tqdm(it):\n",
    "    i += 1\n",
    "    jj = alg.model.distilbert(batch[0][:,:,0].cuda(), batch[0][:,:,1].cuda())['last_hidden_state']\n",
    "    kk = jj[:,0].detach().cpu()\n",
    "    all_feats.append(np.array(kk))\n",
    "    all_labels.append(batch[1].cpu().numpy())\n",
    "    metadata.append(batch[2].cpu().numpy())\n",
    "    toxicity.append(batch[2].cpu().numpy()[:,-1])\n",
    "all_feats = np.concatenate(all_feats, axis=0)\n",
    "metadata = np.concatenate(metadata)\n",
    "toxicity = np.concatenate(toxicity)\n",
    "y = data.y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88657fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [full_dataset._text_array[i] for i in data.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e37718",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = full_dataset._metadata_fields\n",
    "data_dir = '../data/real_true_labels/content_mod/' + str(thresh) + '/'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "np.save(data_dir + '/vals.npz' , all_feats)\n",
    "np.save(data_dir + '/metadata_col_names', annotations)\n",
    "np.save(data_dir + '/metadata', metadata)\n",
    "np.save(data_dir + '/toxicity', toxicity)\n",
    "np.save(data_dir + '/observed_labels', y)\n",
    "np.save(data_dir + '/text', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0367632",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_reps), all_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082640e",
   "metadata": {},
   "source": [
    "### Save version with a single annotator's label for toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687ec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef57e9d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
